---
layout: distill
title: 6.S898 Project Proposal
description: Exploring musical timbre transfer by leveraging prior art in differential digital signal processing (DDSP) and modern deep learning structures. Or, exploring techniques for running deep learning models on consumer-grade hardware and even microcontrollers.
date: 2023-11-09
htmlwidgets: true

authors:
  - name: Yohan Guyomard
    url: "https://yohandev.github.io"
    affiliations:
      name: MIT

bibliography: 2023-11-09-ddsp-proposal.bib

toc:
  - name: (Meta) Structure of this Proposal
  - name: (Idea 0) Deep Learning for Signal Processing
  - name: (Idea 1) Deep Learning for the Modest Computer
---

## (Meta) Structure of this Proposal
Hello! I have two directions for this project which I outline below; let me know how I could improve on either, or which is best suited for the class.

## (Idea #0) Deep Learning for Signal Processing
Exploring the use of deep learning models in signal processing, specifically with the musical application of timbre transfer. That is, transforming some audio clip while retaining every perceivable property except timbre (e.g. trumpet to violin). This exploration will largely build off [Magenta's DDSP paper](https://magenta.tensorflow.org/ddsp) from 2020 and consist of a digestible explanation of the concepts involved (spectrogram loss, harmonic oscillators, differentiable filters) and an alternative implementation using mechanisms taught in class. Some examples of this:
- Modify the encoder/decoder. Save for the DSP components, I think the architecture for this model can be very flexible (in layman's terms, we are training a model to turn the knobs of a synth in realtime) so there's a lot of room for play in between.
  - The original paper explicitely encodes pitch, amplitude and an (optional) time-dependent embedding, but is all of this needed? Do models perform better completely unsupervised?
- The original paper uses GRUs just about everywhere, which makes sense, but could a transformer be useful here?
- Ditch additive synthesis altogether but retain the advantages of this paper with regard to neural audio synthesis (discussed therein).
  - Train a network to manipulate parameters on filters that operate on the source audio input?
    - Potential implementation: kind of like stable diffusion, randomly destroy the input signal (with additive noise but also \[subtractive\] DSP filters) and train a model to recover the original sound.
    - Has the advantage of being much more faithful to the original signal (e.g. more expressivity) since the original paper's encoder is rather reductive (pitch, amplitude)

Regardless of which guiding question I pursue, this would make for a really fun interactive blog. The final submission will include an in-browser DSP that allows users to play with and form an intuition for what parameters the neural network is touching (e.g. an array of sliders for a harmonic oscillator).

## (Idea #1) Deep Learning for the Modest Computer
Overview of modern methods for adapting deep learning to consumer hardware and even microcontrollers. Demonstration of (faster, better?) alternatives to PyTorch, namely implemented in Rust. Large emphasis on quantization and how far it can be pushed. How practical is deep learning with fixed point arithmetic for platforms without FPUs (e.g. many microcontrollers). A slightly more defined plan for this:
- Quantization, or, billions of parameters running in the web (WebAssembly). In-depth explanation of how this works and has been used in LLMs like `llama.cpp`. Some exploration in extreme cases of this, e.g. is a 1 bit neural network any useful?
  - Adapting a large language model for the Raspberry Pi Pico, e.g. "GPT on $4"
    - Fixed point arithmetic... selective, or at every step?
    - On a side note I've been working on [pushing this hardware to its limits](https://yohandev.github.io/portfolio/picocraft/) so I have *(some)* faith that this is at all possible.
    - If this works on the microcontroller, a similar web-demo would run at staggering speeds.
- Demonstration of novel deep learning frameworks, namely HuggingFace's `candle`. There's been a leap in ergonomic APIs in strongly-typed languages which already have so many advantages over Python. It's also unlikely that PyTorch will ever run client-side web, let alone on embedded systems.