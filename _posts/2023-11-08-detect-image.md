---
layout: distill
title: Zero-Shot Machine-Generated Image Detection using Sinks of Gradient Flows
description: "How can we detect fake images online? A novel approach of characterizing the behavior of a diffusion model's learned score vectors."
date: 2023-11-08
htmlwidgets: true

# Anonymize when submitting
# authors:
#   - name: Anonymous

authors:
  - name: Marvin Li
    url: ""
    affiliations:
      name: Harvard
  - name: Jason Wang
    url: ""
    affiliations:
      name: Harvard

# must be the exact same name as your blogpost
bibliography: 2023-11-08-detect-image.bib  

# Add a table of contents to your post.
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
toc:
  - name: Project Proposal

# Below is an example of injecting additional post-specific styles.
# This is used in the 'Layouts' section of this post.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

#### Project Proposal

As AI-generated images become ever more widespread, garnering virality for how realistic they have become, we are increasingly concerned with the potential for misuse. For example, a deluge of machine-generated fake images could spread misinformation and harmful content on social media. Consequently, a growing body of research has sought to develop technqiues to distinguish between the real and the synthetic.

In this project, we are interested in developing techniques to detect images generated from diffusion models, the most prevalent image generation architecture. In particular, we are inspired by ideas from DetectGPT <d-cite key="mitchell2023detectgpt"></d-cite>, a recent work which addressed the same problem of detecting AI-generated content, but in the setting of large language models. For a given piece of text, DetectGPT perturbs the original text and computes the difference in log-likelihood between the perturbed text and the original text:

$$\mathrm{DetectGPT}(x,p_{\theta},q)\triangleq\log p_{\theta}(x)-\mathbb{E}_{\tilde{x}\sim q(\cdot|x)}\log p_{\theta}(\tilde{x})$$

where $$p_\theta$$ is the language model and $$q$$ is the distribution of perturbations. If the difference in log-likelihood is large, then the attack claims that the original text is more likely to be generated by a language model. We are interested in extending this idea to develop a similar method for diffusion models.

There are several critical differences between language models and diffusion models. With text, one can directly compute the log likelihood of a given piece of text, even with only blackbox access, i.e., no visibility to the model's parameters. In contrast, for diffusion models, it is intractable to directly compute the probability distribution over images because diffusion models only learn the score. Moreover, the most commonly used diffusion models, e.g. DALL-E 3, apply the diffusion process to a latent embedding space rather than the pixel space. To address the latter concern, we plan on applying the encoder to the image to obtain an approximation of the embedding that was passed into the decoder. And to address the former, instead of approximating the probability curvature around a given point like DetectGPT, we formulate a statistic characterizing whether the gradient field/score is a sink, i.e., the gradients around a machine-generated image point to the machine-generated image. This captures the idea of a local maximum in probability space, similar to the DetectGPT framework. In particular, we would like to compute the divergence of the diffusion model's score field around the image (negative divergence indicates a sink). We can estimate this via a finite-differencing approach: given a diffusion model $s_\theta(x)$ which predicts the score $\nabla_x\log p_\theta(x)$, we have that

$$\mathrm{div}(s_\theta,x)\approx \sum_{i=1}^d \frac{s_\theta(x+he_i)-s_\theta(x-he_i)}{2h}$$

for $$h$$ small enough and $\\{e_i\\}_{i=1}^d$ an orthonormal basis.
However, images tend to be incredibly high-dimensional, which means that this sum could be computationally expensive; although, for models that apply the diffusion process on the latent embedding space this may be more feasible. Alternatively, we can get a characterization of the score field by noising the image/latent, and then denoising with the diffusion models and measuring the average distance back to the original data point. That is, given a diffusion model $$f_\theta$$ which takes a noised image and outputs an unnoised image (abstracting away noise schedulers, etc. for clarity),

$$\mathrm{DetectImage}(f_{\theta},x)\triangleq \mathbb{E}_{\tilde{x}\sim \mathcal{N}(x,\epsilon)}||x-f_{\theta}(\tilde{x})||_2$$

for $$\epsilon$$ small enough (though it might be interesting to characterize across different $$\epsilon$$).

Previous literature has considered several different methods for image detection. Sha et al. 2023 <d-cite key="sha2022fake"></d-cite> trained machine learning classifiers to detect fake images using high-level image and text embeddings. They, however, do not consider the local information around image embeddings, and require existing datasets of known image-generated and non-image-generated examples to train their classifier. Corvi et al. 2023 <d-cite key="corvi2023detection"></d-cite> identified "forensic traces" in machine-generated image residuals for this task. Again, their method requires many data samples, and performs much worse on diffusion models than GANs. In principle, as with DetectGPT, our score-based image detection algorithm will be zero-shot, will require no additional datasets (beyond evaluating the performance), and will be generalizable across different diffusion models.

Our project plan is thus the following:

1. *Dataset.* We plan to use the DiffusionDB dataset <d-cite key="wang2022diffusiondb"></d-cite>, a dataset of 14M (prompt, image) pairs generated by the open-source Stable Diffusion Version 1 model <d-cite key="rombach2022high"></d-cite>. We then use the MSCOCO dataset <d-cite key="lin2014microsoft"></d-cite>, a dataset of 330K non-machine generated images, which was used by Sha et al. <d-cite key="sha2022fake"></d-cite> in their evaluation.
2. *Implementation.* We will implement the two proposed statistics that uses the score information around generated images to predict whether it was generated by a model. We will also continue to look at existing definitions/characterizations of sinks in existing literature. Then, we will rigorously test over the size of the neighborhood to examine to determine the best parameters for the method.
3. *Comparison.* We plan to compare our method to the existing methods we mentioned before. In each case, we want to calculate the accuracy and full AUC-ROC curve, and in particular, we are concerned with the low FPR rates where we are quite sure an image is fake. We also want to test the robustness of our method to random image cropping, noising, reflections, rotations, and compression. We plan to run image augmentations over both our datasets and report the same metrics over these augmentations.