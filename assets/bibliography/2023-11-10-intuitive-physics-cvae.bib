
@article{piloto_intuitive_2022,
	title = {Intuitive physics learning in a deep-learning model inspired by developmental psychology},
	volume = {6},
	copyright = {2022 The Author(s)},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-022-01394-8},
	doi = {10.1038/s41562-022-01394-8},
	abstract = {‘Intuitive physics’ enables our pragmatic engagement with the physical world and forms a key component of ‘common sense’ aspects of thought. Current artificial intelligence systems pale in their understanding of intuitive physics, in comparison to even very young children. Here we address this gap between humans and machines by drawing on the field of developmental psychology. First, we introduce and open-source a machine-learning dataset designed to evaluate conceptual understanding of intuitive physics, adopting the violation-of-expectation (VoE) paradigm from developmental psychology. Second, we build a deep-learning system that learns intuitive physics directly from visual data, inspired by studies of visual cognition in children. We demonstrate that our model can learn a diverse set of physical concepts, which depends critically on object-level representations, consistent with findings from developmental psychology. We consider the implications of these results both for AI and for research on human cognition.},
	language = {en},
	number = {9},
	urldate = {2023-11-09},
	journal = {Nature Human Behaviour},
	author = {Piloto, Luis S. and Weinstein, Ari and Battaglia, Peter and Botvinick, Matthew},
	month = sep,
	year = {2022},
	note = {Number: 9
Publisher: Nature Publishing Group},
	keywords = {Cognitive neuroscience, Computational models, Philosophy, Psychology},
	pages = {1257--1267},
	file = {Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\YAZ3GXFX\\Piloto et al. - 2022 - Intuitive physics learning in a deep-learning mode.pdf:application/pdf},
}

@article{hubel_brain_1979,
	title = {Brain {Mechanisms} of {Vision}},
	volume = {241},
	issn = {0036-8733},
	url = {https://www.scientificamerican.com/article/brain-mechanisms-of-vision},
	doi = {10.1038/scientificamerican0979-150},
	language = {en},
	number = {3},
	urldate = {2023-11-11},
	journal = {Scientific American},
	author = {Hubel, David H. and Wiesel, Torsten N.},
	month = sep,
	year = {1979},
	pages = {150--162},
	file = {Hubel and Wiesel - 1979 - Brain Mechanisms of Vision.pdf:C\:\\Users\\eliu\\Zotero\\storage\\TLT46YLE\\Hubel and Wiesel - 1979 - Brain Mechanisms of Vision.pdf:application/pdf},
}

@article{rosenblatt_perceptron_1958,
	title = {The perceptron: {A} probabilistic model for information storage and organization in the brain},
	volume = {65},
	issn = {1939-1471},
	shorttitle = {The perceptron},
	doi = {10.1037/h0042519},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Brain, Cognition, Memory, Nervous System},
	pages = {386--408},
	file = {Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\7YMQKUFI\\1959-09865-001.html:text/html},
}

@article{yildirim_efficient_2020,
	title = {Efficient inverse graphics in biological face processing},
	volume = {6},
	url = {https://www.science.org/doi/10.1126/sciadv.aax5979},
	doi = {10.1126/sciadv.aax5979},
	abstract = {Vision not only detects and recognizes objects, but performs rich inferences about the underlying scene structure that causes the patterns of light we see. Inverting generative models, or “analysis-by-synthesis”, presents a possible solution, but its mechanistic implementations have typically been too slow for online perception, and their mapping to neural circuits remains unclear. Here we present a neurally plausible efficient inverse graphics model and test it in the domain of face recognition. The model is based on a deep neural network that learns to invert a three-dimensional face graphics program in a single fast feedforward pass. It explains human behavior qualitatively and quantitatively, including the classic “hollow face” illusion, and it maps directly onto a specialized face-processing circuit in the primate brain. The model fits both behavioral and neural data better than state-of-the-art computer vision models, and suggests an interpretable reverse-engineering account of how the brain transforms images into percepts.},
	number = {10},
	urldate = {2023-11-11},
	journal = {Science Advances},
	author = {Yildirim, Ilker and Belledonne, Mario and Freiwald, Winrich and Tenenbaum, Josh},
	month = mar,
	year = {2020},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaax5979},
	file = {Full Text PDF:C\:\\Users\\eliu\\Zotero\\storage\\KE8LQ42A\\Yildirim et al. - 2020 - Efficient inverse graphics in biological face proc.pdf:application/pdf},
}

@misc{meng_locating_2023,
	title = {Locating and {Editing} {Factual} {Associations} in {GPT}},
	url = {http://arxiv.org/abs/2202.05262},
	doi = {10.48550/arXiv.2202.05262},
	abstract = {We analyze the storage and recall of factual associations in autoregressive transformer language models, finding evidence that these associations correspond to localized, directly-editable computations. We first develop a causal intervention for identifying neuron activations that are decisive in a model's factual predictions. This reveals a distinct set of steps in middle-layer feed-forward modules that mediate factual predictions while processing subject tokens. To test our hypothesis that these computations correspond to factual association recall, we modify feed-forward weights to update specific factual associations using Rank-One Model Editing (ROME). We find that ROME is effective on a standard zero-shot relation extraction (zsRE) model-editing task, comparable to existing methods. To perform a more sensitive evaluation, we also evaluate ROME on a new dataset of counterfactual assertions, on which it simultaneously maintains both specificity and generalization, whereas other methods sacrifice one or another. Our results confirm an important role for mid-layer feed-forward modules in storing factual associations and suggest that direct manipulation of computational mechanisms may be a feasible approach for model editing. The code, dataset, visualizations, and an interactive demo notebook are available at https://rome.baulab.info/},
	urldate = {2023-11-11},
	publisher = {arXiv},
	author = {Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
	month = jan,
	year = {2023},
	note = {arXiv:2202.05262 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, I.2.7},
	file = {arXiv Fulltext PDF:C\:\\Users\\eliu\\Zotero\\storage\\ZNFEKKR2\\Meng et al. - 2023 - Locating and Editing Factual Associations in GPT.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\I2CTLC8J\\2202.html:text/html},
}

@article{olah_zoom_2020,
	title = {Zoom {In}: {An} {Introduction} to {Circuits}},
	volume = {5},
	issn = {2476-0757},
	shorttitle = {Zoom {In}},
	url = {https://distill.pub/2020/circuits/zoom-in},
	doi = {10.23915/distill.00024.001},
	abstract = {By studying the connections between neurons, we can find meaningful algorithms in the weights of neural networks.},
	language = {en},
	number = {3},
	urldate = {2023-11-11},
	journal = {Distill},
	author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
	month = mar,
	year = {2020},
	pages = {e00024.001},
	file = {Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\FZZ8VGQH\\zoom-in.html:text/html},
}

@article{spelke_core_2007,
	title = {Core knowledge},
	volume = {10},
	issn = {1363-755X, 1467-7687},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00569.x},
	doi = {10.1111/j.1467-7687.2007.00569.x},
	abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a ﬁfth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
	language = {en},
	number = {1},
	urldate = {2023-11-11},
	journal = {Developmental Science},
	author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
	month = jan,
	year = {2007},
	pages = {89--96},
	file = {Spelke and Kinzler - 2007 - Core knowledge.pdf:C\:\\Users\\eliu\\Zotero\\storage\\WUIXLUGR\\Spelke and Kinzler - 2007 - Core knowledge.pdf:application/pdf},
}

@misc{babaeizadeh_stochastic_2018,
	title = {Stochastic {Variational} {Video} {Prediction}},
	url = {http://arxiv.org/abs/1710.11252},
	doi = {10.48550/arXiv.1710.11252},
	abstract = {Predicting the future in real-world settings, particularly from raw sensory observations such as images, is exceptionally challenging. Real-world events can be stochastic and unpredictable, and the high dimensionality and complexity of natural images requires the predictive model to build an intricate understanding of the natural world. Many existing methods tackle this problem by making simplifying assumptions about the environment. One common assumption is that the outcome is deterministic and there is only one plausible future. This can lead to low-quality predictions in real-world settings with stochastic dynamics. In this paper, we develop a stochastic variational video prediction (SV2P) method that predicts a different possible future for each sample of its latent variables. To the best of our knowledge, our model is the first to provide effective stochastic multi-frame prediction for real-world video. We demonstrate the capability of the proposed method in predicting detailed future frames of videos on multiple real-world datasets, both action-free and action-conditioned. We find that our proposed method produces substantially improved video predictions when compared to the same model without stochasticity, and to other stochastic video prediction methods. Our SV2P implementation will be open sourced upon publication.},
	urldate = {2023-11-11},
	publisher = {arXiv},
	author = {Babaeizadeh, Mohammad and Finn, Chelsea and Erhan, Dumitru and Campbell, Roy H. and Levine, Sergey},
	month = mar,
	year = {2018},
	note = {arXiv:1710.11252 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {arXiv Fulltext PDF:C\:\\Users\\eliu\\Zotero\\storage\\UFF5MYEI\\Babaeizadeh et al. - 2018 - Stochastic Variational Video Prediction.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\CENRZZY6\\1710.html:text/html},
}

@article{kubricht_intuitive_2017,
	title = {Intuitive {Physics}: {Current} {Research} and {Controversies}},
	volume = {21},
	issn = {1364-6613},
	shorttitle = {Intuitive {Physics}},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661317301262},
	doi = {10.1016/j.tics.2017.06.002},
	abstract = {Early research in the field of intuitive physics provided extensive evidence that humans succumb to common misconceptions and biases when predicting, judging, and explaining activity in the physical world. Recent work has demonstrated that, across a diverse range of situations, some biases can be explained by the application of normative physical principles to noisy perceptual inputs. However, it remains unclear how knowledge of physical principles is learned, represented, and applied to novel situations. In this review we discuss theoretical advances from heuristic models to knowledge-based, probabilistic simulation models, as well as recent deep-learning models. We also consider how recent work may be reconciled with earlier findings that favored heuristic models.},
	number = {10},
	urldate = {2023-11-11},
	journal = {Trends in Cognitive Sciences},
	author = {Kubricht, James R. and Holyoak, Keith J. and Lu, Hongjing},
	month = oct,
	year = {2017},
	keywords = {computation, intuitive physics, mental simulation, misconceptions, probabilistic simulation},
	pages = {749--759},
	file = {ScienceDirect Snapshot:C\:\\Users\\eliu\\Zotero\\storage\\NYCICCJ6\\S1364661317301262.html:text/html},
}
